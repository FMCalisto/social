# Intro

## Prompt 1

Write me 5 good posts about my paper on Facebook. I will provide the abstract of the paper. I also will provide you the DOI link to the paper, which you must include in all posts. Try to be provocative, but not too much. Max 1000 characters. Use good hashtags.

Abstract

**[ABSTRACT]**

DOI link:

**[DOI]**

## Prompt 2

Write me **N** good posts about my papers on Facebook. You need to write one post per each paper. I will provide the abstracts of the papers. I also will provide you the DOI links to the papers, which you must include in all posts. Try to be provocative, but not too much. Max 5000 characters. Use good hashtags.

Abstract

**[ABSTRACT]**

DOI link:

**[DOI]**

### Example 2.1.

Write me 8 good posts about my papers on Facebook. You need to write one post per each paper. I will provide the abstracts of the papers. I also will provide you the DOI links to the papers, which you must include in all posts. Try to be provocative, but not too much. Max 5000 characters. Use good hashtags.

Abstract

Intelligent agents are showing increasing promise for clinical decision-making in a variety of healthcare settings. While a substantial body of work has contributed to the best strategies to convey these agents’ decisions to clinicians, few have considered the impact of personalizing and customizing these communications on the clinicians’ performance and receptiveness. This raises the question of how intelligent agents should adapt their tone in accordance with their target audience. We designed two approaches to communicate the decisions of an intelligent agent for breast cancer diagnosis with different tones: a suggestive (non-assertive) tone and an imposing (assertive) one. We used an intelligent agent to inform about: (1) number of detected findings; (2) cancer severity on each breast and per medical imaging modality; (3) visual scale representing severity estimates; (4) the sensitivity and specificity of the agent; and (5) clinical arguments of the patient, such as pathological co-variables. Our results demonstrate that assertiveness plays an important role in how this communication is perceived and its benefits. We show that personalizing assertiveness according to the professional experience of each clinician can reduce medical errors and increase satisfaction, bringing a novel perspective to the design of adaptive communication between intelligent agents and clinicians.

DOI link:

https://doi.org/10.1145/3544548.3580682

Abstract

The results of this study suggest that while the tool demonstrates a relatively high level of accuracy compared to the original radiologist's density assessment in distinguishing between dense and non-dense breasts, it may have limitations in accurately classifying the specific BI-RADS density categories. This can be seen from the lower mean accuracy of 56.7% and mean agreement of 0.325 when distinguishing between the four BI-RADS categories. Pronounced variation of accuracy scores was found regarding individual radiologist assessments and the algorithm prediction, highlighting the importance of considering individual differences when evaluating the accuracy of assessments, and emphasizing the need for further research in this field.

DOI link:

https://dx.doi.org/10.26044/ecr2023/C-16014

Abstract

Artificial intelligence has the potential to transform many application domains fundamentally. One notable example is clinical radiology. A growing number of decision-making support systems are available for lesion detection and segmentation, two fundamental steps to accomplish diagnosis and treatment planning. This paper proposes a model based on the unified theory of acceptance and use of technology to study the determinants for the adoption of intelligent agents across the medical imaging workflow. We tested the model via confirmatory factor analysis and structural equation modeling using clinicians’ data from an international evaluation of healthcare practitioners. Results show an increased understanding of the vital role of security, risk, and trust in the usage intention of intelligent agents. These empirical findings provide valuable theoretical contributions to researchers by explaining the reasons behind the adoption and usage of intelligent agents in the medical imaging workflow.

DOI link:

https://doi.org/10.1016/j.ijhcs.2022.102922

Abstract

In this paper, we developed BreastScreening-AI within two scenarios for the classification of multimodal beast images: (1) Clinician-Only; and (2) Clinician-AI. The novelty relies on the introduction of a deep learning method into a real clinical workflow for medical imaging diagnosis. We attempt to address three high-level goals in the two above scenarios. Concretely, how clinicians: i) accept and interact with these systems, revealing whether are explanations and functionalities required; ii) are receptive to the introduction of AI-assisted systems, by providing benefits from mitigating the clinical error; and iii) are affected by the AI assistance. We conduct an extensive evaluation embracing the following experimental stages: (a) patient selection with different severities, (b) qualitative and quantitative analysis for the chosen patients under the two different scenarios. We address the high-level goals through a real-world case study of 45 clinicians from nine institutions. We compare the diagnostic and observe the superiority of the Clinician-AI scenario, as we obtained a decrease of 27% for False-Positives and 4% for False-Negatives. Through an extensive experimental study, we conclude that the proposed design techniques positively impact the expectations and perceptive satisfaction of 91% clinicians, while decreasing the time-to-diagnose by 3 min per patient.

DOI link:

https://doi.org/10.1016/j.artmed.2022.102285

Abstract

In this research, we take an HCI perspective on the opportunities provided by AI techniques in medical imaging, focusing on workflow efficiency and quality, preventing errors and variability of diagnosis in Breast Cancer. Starting from a holistic understanding of the clinical context, we developed BreastScreening to support Multimodality and integrate AI techniques (using a deep neural network to support automatic and reliable classification) in the medical diagnosis workflow. This was assessed by using a significant number of clinical settings and radiologists. Here we present: i) user study findings of 45 physicians comprising nine clinical institutions; ii) list of design recommendations for visualization to support breast screening radiomics; iii) evaluation results of a proof-of-concept BreastScreening prototype for two conditions Current (without AI assistant) and AI-Assisted; and iv) evidence from the impact of a Multimodality and AI-Assisted strategy in diagnosing and severity classification of lesions. The above strategies will allow us to conclude about the behaviour of clinicians when an AI module is present in a diagnostic system. This behaviour will have a direct impact in the clinicians workflow that is thoroughly addressed herein. Our results show a high level of acceptance of AI techniques from radiologists and point to a significant reduction of cognitive workload and improvement in diagnosis execution.

DOI link:

https://doi.org/10.1016/j.ijhcs.2021.102607

Abstract

This paper describes the field research, design and comparative deployment of a multimodal medical imaging user interface for breast screening. The main contributions described here are threefold: 1) The design of an advanced visual interface for multimodal diagnosis of breast cancer (BreastScreening); 2) Insights from the field comparison of Single-Modality vs Multi-Modality screening of breast cancer diagnosis with 31 clinicians and 566 images; and 3) The visualization of the two main types of breast lesions in the following image modalities: (i) MammoGraphy (MG) in both Craniocaudal (CC) and Mediolateral oblique (MLO) views; (ii) UltraSound (US); and (iii) Magnetic Resonance Imaging (MRI). We summarize our work with recommendations from the radiologists for guiding the future design of medical imaging interfaces.

DOI link:

https://doi.org/10.1145/3399715.3399744

Abstract

A fundamental step in medical diagnosis for patient follow-up relies on the ability of radiologists to perform a trusty diagnostic from acquired images. Basically, the diagnosis strongly depends on the visual inspection over the shape of the lesions. As datasets increase in size, such visual evaluation becomes harder. For this reason, it is crucial to introduce easy-to-use interfaces that help the radiologists to perform a reliable visual inspection and allow the efficient delineation of the lesions. We will explore the radiologist's receptivity to the current touch environment solution. The advantages of touch are threefold: (i) the time performance is superior regarding the traditional use, (ii) it has more intuitive control and, (iii) for less time, the user interface delivers more information per action, concerning annotations. From our studies, we conclude that the radiologists still exhibit a resistance to change from traditional to touch based interfaces in current clinical setups.

DOI link:

https://doi.org/10.1145/3132272.3134111
